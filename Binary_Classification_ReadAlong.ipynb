{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hPRKWY816RZT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Basics"
      ],
      "metadata": {
        "id": "hPRKWY816RZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting data - just run this cell!\n"
      ],
      "metadata": {
        "id": "zIm5dlZ-GCx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Helper plotting functions - just run this cell and we will use these later\n",
        "def plot_logreg(X, y, y_pred=None, title=\"\"):\n",
        "\n",
        "  correct = y_pred == y\n",
        "  incorrect = y_pred != y\n",
        "  if y_pred is None:\n",
        "    plt.scatter(X[y==0, 0], X[y==0, 1], c='r', marker='o', label='Label 0')\n",
        "    plt.scatter(X[y==1, 0], X[y==1, 1], c='m', marker='o', label='Label 1')\n",
        "  else:\n",
        "    # Plot correct classifications\n",
        "    plt.scatter(X[correct & (y_pred==0), 0], X[correct & (y_pred==0), 1], c='r', marker='o', label='Correct Label 0')\n",
        "    plt.scatter(X[correct & (y_pred==1), 0], X[correct & (y_pred==1), 1], c='m', marker='o', label='Correct Label 1')\n",
        "\n",
        "    # Plot incorrect classifications\n",
        "    plt.scatter(X[incorrect & (y_pred==0), 0], X[incorrect & (y_pred==0), 1], c='m', marker='x', s=100, label='Incorrect Label 0')\n",
        "    plt.scatter(X[incorrect & (y_pred==1), 0], X[incorrect & (y_pred==1), 1], c='r', marker='x', s=100, label='Incorrect Label 1')\n",
        "\n",
        "  plt.xlabel('Feature 1')\n",
        "  plt.ylabel('Feature 2')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "def plot_boundary(model, xmin, xmax, ymin, ymax):\n",
        "  b = model.intercept_[0]\n",
        "  w1, w2 = model.coef_.T\n",
        "\n",
        "  c = -b/w2\n",
        "  m = -w1/w2\n",
        "  xd = np.array([xmin, xmax])\n",
        "  yd = m*xd + c\n",
        "  plt.plot(xd, yd, 'k', lw=1, ls='--')\n",
        "  plt.fill_between(xd, yd, ymin, color='tab:blue', alpha=0.2)\n",
        "  plt.fill_between(xd, yd, ymax, color='tab:orange', alpha=0.2)\n",
        "\n",
        "def plot_mlp_decisions(X, model, cmap=plt.cm.RdYlBu, buffer=.5):\n",
        "  # Create a mesh to plot in\n",
        "  x_min, x_max = X[:, 0].min() - buffer, X[:, 0].max() + buffer\n",
        "  y_min, y_max = X[:, 1].min() - buffer, X[:, 1].max() + buffer\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                      np.arange(y_min, y_max, 0.01))\n",
        "\n",
        "  # Predict the function value for the whole grid\n",
        "  Z = model_neural.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "\n",
        "  # Plot the contour and training examples\n",
        "  # plot_logreg(X_test, y_test, y_pred, title=\"Predictions on Test Data\")\n",
        "  plt.contourf(xx, yy, Z, cmap=cmap, alpha=0.3)"
      ],
      "metadata": {
        "id": "58Gz5ctI7QBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at some synthetic data - run the below code. How would you draw a line to separate the data?"
      ],
      "metadata": {
        "id": "Efha4uqY7mM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_blobs, make_circles\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X, y = make_blobs(n_samples=1000, centers=2, random_state=0, cluster_std=1.30)\n",
        "y_sort_indices = np.argsort(y)\n",
        "X = X[y_sort_indices]\n",
        "y = y[y_sort_indices]\n",
        "\n",
        "\n",
        "def plot_logreg(X, y, y_pred=None, title=\"\", mode='linear'):\n",
        "\n",
        "  correct = y_pred == y\n",
        "  incorrect = y_pred != y\n",
        "  if y_pred is None:\n",
        "    plt.scatter(X[y==0, 0], X[y==0, 1], c='r', marker='o', label='Label 0')\n",
        "    plt.scatter(X[y==1, 0], X[y==1, 1], c='m', marker='o', label='Label 1')\n",
        "  else:\n",
        "    # Plot correct classifications\n",
        "    plt.scatter(X[correct & (y_pred==0), 0], X[correct & (y_pred==0), 1], c='r', marker='o', label='Correct Label 0')\n",
        "    plt.scatter(X[correct & (y_pred==1), 0], X[correct & (y_pred==1), 1], c='m', marker='o', label='Correct Label 1')\n",
        "\n",
        "    # Plot incorrect classifications\n",
        "    plt.scatter(X[incorrect & (y_pred==0), 0], X[incorrect & (y_pred==0), 1], c='m', marker='x', s=100, label='Incorrect Label 0')\n",
        "    plt.scatter(X[incorrect & (y_pred==1), 0], X[incorrect & (y_pred==1), 1], c='r', marker='x', s=100, label='Incorrect Label 1')\n",
        "\n",
        "  plt.xlabel('Feature 1')\n",
        "  plt.ylabel('Feature 2')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "plot_logreg(X, y, title=\"Synthetic Data in Two Blobs\")"
      ],
      "metadata": {
        "id": "YVAebXdT6qVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If we know where the data is coming from, we can sometimes come up with an optimal answer! But usually we don't. The main goal of machine learning is to learn what is generating our data so we can infer about unseen circumstances"
      ],
      "metadata": {
        "id": "gVq5DGSsU5tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "center1 = np.mean(X[y==0], axis=0)\n",
        "center2 = np.mean(X[y==1], axis=0)\n",
        "midpoint = (center1 + center2) / 2\n",
        "direction =  (center1 - center2)\n",
        "direction = -1*direction[0] / direction[1]\n",
        "intercept = midpoint[1] - direction * midpoint[0]\n",
        "\n",
        "\n",
        "xd = np.array([-3, 7])\n",
        "plt.plot(xd, (direction)*xd + intercept, ls=':', label='Optimal Decision Boundary')\n",
        "plot_logreg(X, y, title=\"Synthetic Data in Two Blobs\")"
      ],
      "metadata": {
        "id": "SG9Ar-YuU1q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember, we want to learn the _data generating function_ not the data. To do that, a common strategy is to split our data randomly into train and test sets."
      ],
      "metadata": {
        "id": "vvVutT5o8h-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "jaWVZ2bhAg-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now we can look at a basic statistical learning package and test some functions"
      ],
      "metadata": {
        "id": "p6pT-Dlh74hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we initialize the model\n",
        "model_logistic1 = LogisticRegression(random_state = 0)\n",
        "# Then we \"fit\" the model - math to learn the data!\n",
        "model_logistic1.fit(X_train, y_train)\n",
        "# Now let's evaluate on the test\n",
        "y_pred = model_logistic1.predict(X_test)\n",
        "\n",
        "def plot_boundary(model, xmin, xmax, ymin, ymax):\n",
        "  b = model.intercept_[0]\n",
        "  w1, w2 = model.coef_.T\n",
        "\n",
        "  c = -b/w2\n",
        "  m = -w1/w2\n",
        "  xd = np.array([xmin, xmax])\n",
        "  yd = m*xd + c\n",
        "  plt.plot(xd, yd, 'k', lw=1, ls='--')\n",
        "  plt.fill_between(xd, yd, ymin, color='tab:blue', alpha=0.2)\n",
        "  plt.fill_between(xd, yd, ymax, color='tab:orange', alpha=0.2)\n",
        "\n",
        "\n",
        "plt.plot(xd, (direction)*xd + intercept, ls=':', label='Optimal Decision Boundary')\n",
        "plot_boundary(model_logistic1, -3, 7, -3, 8)\n",
        "plot_logreg(X_test, y_test, y_pred, title=\"Predictions on Test Data\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xVA50LOE7372"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now let's look at some key machine learning intuitions that should influence how you set up machine learning problems.\n",
        "# First, let's take away some of the data of label 2 - will we still learn the same line?"
      ],
      "metadata": {
        "id": "pjBwSozKKpKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of examples in label 1: {(y==0).sum()}. Number of examples in label 2: {(y==1).sum()}\")"
      ],
      "metadata": {
        "id": "1pxM7nhKMYvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d4d937-f0d6-4782-e836-ee2d543906f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples in label 1: 500. Number of examples in label 2: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_class_imbalance, y_class_imbalance = X[:int(X.shape[0]*.6)], y[:int(y.shape[0]*.6)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_class_imbalance, y_class_imbalance, test_size=0.2, random_state=42)\n",
        "\n",
        "b, w = model_logistic1.intercept_[0], model_logistic1.coef_[0]\n",
        "c = -b/w[1]\n",
        "m = -w[0]/w[1]\n",
        "xd = np.array([-3, 7])\n",
        "yd = m*xd + c\n",
        "plt.plot(xd, yd, 'b', lw=1, ls='--', label=\"Original Decision Boundary\")\n",
        "# First we initialize the model\n",
        "model_logistic = LogisticRegression(random_state = 0)\n",
        "# Then we \"fit\" the model - math to learn the data!\n",
        "model_logistic.fit(X_train, y_train)\n",
        "# Now let's evaluate on the test\n",
        "y_pred = model_logistic.predict(X_test)\n",
        "\n",
        "plot_boundary(model_logistic, -3, 7, -3, 8)\n",
        "plot_logreg(X_test, y_test, y_pred, \"Predictions on Test Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lMLWsSRvLybW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What if we repeat our minority label?"
      ],
      "metadata": {
        "id": "a2mqWy3BYb6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_minority_class, y_minority_class = X_class_imbalance[y_class_imbalance==1], y_class_imbalance[y_class_imbalance==1]\n",
        "X_rebalanced = np.concatenate([X_class_imbalance, X_minority_class.repeat(4, axis=0)])\n",
        "y_rebalanced = np.concatenate([y_class_imbalance, y_minority_class.repeat(4, axis=0)])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_rebalanced, y_rebalanced, test_size=0.2, random_state=42)\n",
        "\n",
        "b, w = model_logistic1.intercept_[0], model_logistic1.coef_[0]\n",
        "c = -b/w[1]\n",
        "m = -w[0]/w[1]\n",
        "xd = np.array([-3, 7])\n",
        "yd = m*xd + c\n",
        "plt.plot(xd, yd, 'b', lw=1, ls='--', label=\"Original Decision Boundary\")\n",
        "# First we initialize the model\n",
        "model_logistic = LogisticRegression(random_state = 0)\n",
        "# Then we \"fit\" the model - math to learn the data!\n",
        "model_logistic.fit(X_train, y_train)\n",
        "# Now let's evaluate on the test\n",
        "y_pred = model_logistic.predict(X_test)\n",
        "\n",
        "plot_boundary(model_logistic, -3, 7, -3, 8)\n",
        "plot_logreg(X_test, y_test, y_pred, \"Predictions on Test Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-4v_KH--YexV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try again - with circles!"
      ],
      "metadata": {
        "id": "lzS2Fw2yBlZo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh-6AouyzZwE"
      },
      "outputs": [],
      "source": [
        "X, y = make_circles(n_samples=1000, noise=0.15, factor=0.25, random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "plot_logreg(X, y, title=\"Synthetic Data in Two Circles\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First we initialize the model\n",
        "model_logistic = LogisticRegression(random_state = 0)\n",
        "# Then we \"fit\" the model - math to learn the data!\n",
        "model_logistic.fit(X_train, y_train)\n",
        "# Now let's evaluate on the test\n",
        "y_pred = model_logistic.predict(X_test)\n",
        "\n",
        "plot_boundary(model_logistic, -2, 2, -2, 2)\n",
        "\n",
        "plot_logreg(X_test, y_test, y_pred, title=\"Predictions on Test Data\")\n",
        "plt.xlim([-2, 2])\n",
        "plt.ylim([-2, 2])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_sQWbjmBe27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We hit our first example of getting hit by our choice of _model class_. Logistic regression creates a linear decision boundary to separate the features. Our circles cannot be classified with a straight line! We need a more complicated set of models!\n",
        "\n",
        "There are many different \"simpler\" models that could classify this data, but since everybody is using them, let's use a simple neural network, also called an MLP, or Multi Layer Perceptron."
      ],
      "metadata": {
        "id": "amooijUtDCYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n"
      ],
      "metadata": {
        "id": "0gqPreSrEmLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The history of neural networks is long and storied, but the basics comes down to this. Imagine we took a bunch of lines and figured out how to stitch them together to separate the inner circle from the outer circle.\n",
        "For a coherent and beautiful visual tutorial, let's visit: https://playground.tensorflow.org/#activation=relu  "
      ],
      "metadata": {
        "id": "ByKEYlYtFCTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's make a new model in code to match the playground\n",
        "# Reading documentation is a very (!!!) important skill.\n",
        "# Visit https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "# to see how to use the function\n",
        "# Note: This is considered a very bare-bones neural network library. For \"big\" data, consider Pytorch\n",
        "\n",
        "model_neural = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000)\n",
        "\n",
        "# Fit the model\n",
        "model_neural.fit(X_train, y_train)\n",
        "\n",
        "# Now let's evaluate on the test\n",
        "y_pred = model_neural.predict(X_test)\n",
        "\n",
        "plot_mlp_decisions(X_train, model_neural, buffer=.25)\n",
        "\n",
        "# Plot the contour and training examples\n",
        "plot_logreg(X_test, y_test, y_pred, title=\"Predictions on Test Data\")\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('MLPClassifier Decision Boundary')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BHngxfTPFKvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... and with class imbalance again"
      ],
      "metadata": {
        "id": "tucWBus4mS93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_sort_indices = np.argsort(y)\n",
        "X_train_circles = X[y_sort_indices]\n",
        "y_train_circles = y[y_sort_indices]\n",
        "\n",
        "X_train_circles = X_train_circles[:int(X_train_circles.shape[0]*.6)]\n",
        "y_train_circles = y_train_circles[:int(y_train_circles.shape[0]*.6)]\n",
        "\n",
        "model_neural = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, shuffle=False)\n",
        "\n",
        "# Fit the model\n",
        "model_neural.fit(X_train_circles, y_train_circles)\n",
        "\n",
        "# Now let's evaluate on the test\n",
        "y_pred = model_neural.predict(X_test)\n",
        "plot_mlp_decisions(X_train, model_neural, buffer=.25)\n",
        "\n",
        "# Plot the contour and training examples\n",
        "plot_logreg(X_test, y_test, y_pred, title=\"Predictions on Test Data\")\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('MLPClassifier Decision Boundary')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YTTm7TetWdK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise! Let's take some unknown data and figure out how to classify it correctly.\n",
        "## These are the answers. For the answer-less assignment, switch to: Binary_Classification_Exercise.ipynb"
      ],
      "metadata": {
        "id": "ttRwtY3GEbOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's load our dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/TuragaLab/jhu-janelia-ml-demo/main/binary_classification.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "LgQs3fl4zerf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "23bdf6ba-13b9-483c-885e-d0657fa89e65"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       attr_0  attr_1  attr_2  attr_3  attr_4  attr_5  attr_6  attr_7  attr_8  \\\n",
              "0       23.15    1.42    0.01  -63.59    3.41   -0.51    1.51    0.02   11.29   \n",
              "1       21.41   -0.02    1.59   -1.01    1.36   -0.25    0.04    0.36   -1.38   \n",
              "2       29.61    0.93    1.51   22.40    8.75   -0.33    0.04   -0.57    0.17   \n",
              "3       19.96   -0.12    2.06    3.20    1.79   -0.13   -0.15    0.64   13.03   \n",
              "4       23.91   15.96    1.93  116.26   44.09   -0.46    0.51   -0.57   16.25   \n",
              "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "99995   32.53   -0.08    0.01    0.04    4.21   -0.38    0.34   -0.15   17.06   \n",
              "99996   27.09   -7.67   56.54    2.25   15.32   -0.50   -0.13    0.84   27.35   \n",
              "99997   27.68    1.42   59.03   88.47   22.11   -0.37    0.54    1.52   -7.37   \n",
              "99998   37.91   -5.78   15.47   -3.88    0.33   -0.52    0.29    1.56   -0.30   \n",
              "99999   25.12   -0.17    0.62   -0.33   10.15   -0.46    0.54   -0.64   11.83   \n",
              "\n",
              "       attr_9  labels  \n",
              "0        1.60     1.0  \n",
              "1       -0.00     1.0  \n",
              "2        4.28     0.0  \n",
              "3        1.67     1.0  \n",
              "4        0.00     0.0  \n",
              "...       ...     ...  \n",
              "99995    0.19     0.0  \n",
              "99996    1.41     0.0  \n",
              "99997    2.20     0.0  \n",
              "99998    0.14     0.0  \n",
              "99999   -4.00     0.0  \n",
              "\n",
              "[100000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-221487fc-32f3-4825-89af-700b3d662ee7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attr_0</th>\n",
              "      <th>attr_1</th>\n",
              "      <th>attr_2</th>\n",
              "      <th>attr_3</th>\n",
              "      <th>attr_4</th>\n",
              "      <th>attr_5</th>\n",
              "      <th>attr_6</th>\n",
              "      <th>attr_7</th>\n",
              "      <th>attr_8</th>\n",
              "      <th>attr_9</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23.15</td>\n",
              "      <td>1.42</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-63.59</td>\n",
              "      <td>3.41</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.02</td>\n",
              "      <td>11.29</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.41</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>1.59</td>\n",
              "      <td>-1.01</td>\n",
              "      <td>1.36</td>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.36</td>\n",
              "      <td>-1.38</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.61</td>\n",
              "      <td>0.93</td>\n",
              "      <td>1.51</td>\n",
              "      <td>22.40</td>\n",
              "      <td>8.75</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>0.17</td>\n",
              "      <td>4.28</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19.96</td>\n",
              "      <td>-0.12</td>\n",
              "      <td>2.06</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1.79</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>0.64</td>\n",
              "      <td>13.03</td>\n",
              "      <td>1.67</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23.91</td>\n",
              "      <td>15.96</td>\n",
              "      <td>1.93</td>\n",
              "      <td>116.26</td>\n",
              "      <td>44.09</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>0.51</td>\n",
              "      <td>-0.57</td>\n",
              "      <td>16.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>32.53</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.04</td>\n",
              "      <td>4.21</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>0.34</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>17.06</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>27.09</td>\n",
              "      <td>-7.67</td>\n",
              "      <td>56.54</td>\n",
              "      <td>2.25</td>\n",
              "      <td>15.32</td>\n",
              "      <td>-0.50</td>\n",
              "      <td>-0.13</td>\n",
              "      <td>0.84</td>\n",
              "      <td>27.35</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>27.68</td>\n",
              "      <td>1.42</td>\n",
              "      <td>59.03</td>\n",
              "      <td>88.47</td>\n",
              "      <td>22.11</td>\n",
              "      <td>-0.37</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1.52</td>\n",
              "      <td>-7.37</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>37.91</td>\n",
              "      <td>-5.78</td>\n",
              "      <td>15.47</td>\n",
              "      <td>-3.88</td>\n",
              "      <td>0.33</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.56</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>25.12</td>\n",
              "      <td>-0.17</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>10.15</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>0.54</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>11.83</td>\n",
              "      <td>-4.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows Ã— 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-221487fc-32f3-4825-89af-700b3d662ee7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-221487fc-32f3-4825-89af-700b3d662ee7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-221487fc-32f3-4825-89af-700b3d662ee7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38503874-2893-46b9-beff-af4a2e7d4ad7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38503874-2893-46b9-beff-af4a2e7d4ad7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38503874-2893-46b9-beff-af4a2e7d4ad7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8fb72e36-3a7e-4f26-b06e-75472133173c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8fb72e36-3a7e-4f26-b06e-75472133173c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"attr_0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.537401085800653,\n        \"min\": 6.86,\n        \"max\": 68.23,\n        \"num_unique_values\": 3956,\n        \"samples\": [\n          25.88,\n          30.0,\n          15.26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.758345593854749,\n        \"min\": -26.58,\n        \"max\": 16.48,\n        \"num_unique_values\": 1957,\n        \"samples\": [\n          -26.35,\n          15.13,\n          5.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 116.603163670414,\n        \"min\": 0.0,\n        \"max\": 2439.82,\n        \"num_unique_values\": 17322,\n        \"samples\": [\n          269.65,\n          686.69,\n          7.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27.49863174581529,\n        \"min\": -234.17,\n        \"max\": 297.89,\n        \"num_unique_values\": 11361,\n        \"samples\": [\n          -0.1,\n          94.33,\n          -37.14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.128341416499028,\n        \"min\": -11.41,\n        \"max\": 86.3,\n        \"num_unique_values\": 5551,\n        \"samples\": [\n          17.93,\n          52.6,\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22028459405683318,\n        \"min\": -0.52,\n        \"max\": 2.17,\n        \"num_unique_values\": 229,\n        \"samples\": [\n          1.83,\n          0.4,\n          -0.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3754308779632161,\n        \"min\": -0.16,\n        \"max\": 2.03,\n        \"num_unique_values\": 176,\n        \"samples\": [\n          0.13,\n          -0.01,\n          1.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7343267862282293,\n        \"min\": -2.65,\n        \"max\": 2.4,\n        \"num_unique_values\": 461,\n        \"samples\": [\n          -1.72,\n          0.42,\n          -0.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.153795705483251,\n        \"min\": -28.58,\n        \"max\": 62.24,\n        \"num_unique_values\": 5420,\n        \"samples\": [\n          38.92,\n          1.95,\n          6.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attr_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9083134772656156,\n        \"min\": -5.56,\n        \"max\": 12.24,\n        \"num_unique_values\": 1177,\n        \"samples\": [\n          3.65,\n          5.94,\n          2.31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4978055500932638,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparing the Data for Classification\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AIss_BM81miE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features (X) and target variable (y)\n",
        "X = np.array(data.iloc[:, :-1])\n",
        "y = np.array(data.iloc[:, -1])\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")"
      ],
      "metadata": {
        "id": "G4R-KOZyzoiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Implementing the Model"
      ],
      "metadata": {
        "id": "vTMD8ztX1r9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "class FirstClassModel:\n",
        "    def __init__(self, model=\"logistic\"):\n",
        "\n",
        "        self.model_neural = MLPClassifier([50, 10], max_iter=50, verbose=True, tol=.00001, random_state=502, learning_rate_init=0.1)\n",
        "        self.model_logistic = LogisticRegression(random_state = 0)\n",
        "\n",
        "        if model == \"logistic\":\n",
        "            self.model = self.model_logistic\n",
        "        elif model == 'neural':\n",
        "            self.model = self.model_neural\n",
        "\n",
        "    def fit(self,x,y):\n",
        "\n",
        "        self.model.fit(x, y)\n",
        "\n",
        "    def predict_class(self,x):\n",
        "        ### This method must return an array with size y\n",
        "        ## whose entries are either 0 or 1#\n",
        "        y_pred = self.model.predict(x)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "    def predict_probabilities(self,x):\n",
        "        ### This method must return an array with size y\n",
        "        ## whose entries denote the \"likelihood\" that input\n",
        "        # x belongs to (each) class, with shape (#data points, #classes)\n",
        "        y_prob = self.model.predict_proba(x)\n",
        "        return y_prob\n",
        "\n",
        "    def performance_metrics(self,x,y):\n",
        "        ### report accuracy, true positive rate, false positive rate\n",
        "        ## as well as score mean and standard deviation (corresponding to class ONE)\n",
        "        # ...\n",
        "        y_pred = self.predict_class(x)\n",
        "        y_prob = self.predict_probabilities(x)\n",
        "        yprob_mean = np.mean(y_prob[:,0])\n",
        "        yprob_stdev = np.std(y_prob[:,0])\n",
        "        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
        "        print(tn, fp, fn, tp)\n",
        "\n",
        "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "        tpr = tp/(tp+fn)\n",
        "        fpr = fp/(fp+tn)\n",
        "        print(\"Accuracy: \", accuracy)\n",
        "        print(\"True Positive Rate: \", tpr)\n",
        "        print(\"False Positive Rate: \", fpr)\n",
        "        print(\"Score Mean: \", yprob_mean)\n",
        "        print(\"Score Standard Deviation: \", yprob_stdev)\n",
        "\n",
        "        return accuracy, tpr, fpr, yprob_mean, yprob_stdev"
      ],
      "metadata": {
        "id": "QmGCFahi1oJX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: instantiate a model. I've already biased you with\n",
        "# one in the constructor\n",
        "fcm = FirstClassModel()\n",
        "\n",
        "### Step 1:  train model\n",
        "## will need to define .fit() method of FirstClassModel\n",
        "# Calling this method will fit parameters of your model\n",
        "fcm.fit(X,y)\n",
        "\n",
        "### Step 3: define prediction methods\n",
        "## one should give the probability associated to class 1, and\n",
        "# the other the discrete class predictions\n",
        "y_probs = fcm.predict_probabilities(X)\n",
        "y_pred = fcm.predict_class(X)\n",
        "\n",
        "# printing for debugging purposes, not needed\n",
        "print(y_probs)\n",
        "\n",
        "### Step 4: define metrics method\n",
        "## evaluate performance\n",
        "metrics = fcm.performance_metrics(X,y)"
      ],
      "metadata": {
        "id": "PcbJcO8k29pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On to more \"complicated\" machine learning- how can we give our statistical learning algorithms a hand in learning data that we know has some structure?"
      ],
      "metadata": {
        "id": "Ia4YwFH9-3yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One anwer is convolution for dealing with data that is changing over time or for images. The idea is that data close to each other - in time (for time sequences) or in space (for images or video) should inform each other at multiple scales. Like how we first look for edges in an image which form faces, arms, and other body parts, which become people, which becomes a crowd of people. We want to help our algorithm to find these features at compose them kind of like we do.\n",
        "\n",
        "1D convolution: https://e2eml.school/convolution_one_d.html\n",
        "\n",
        "2D convolution: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1"
      ],
      "metadata": {
        "id": "hIzWdswI_A1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "lA0eHNhC_AV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To do this, we will implement Pytorch, the most popular neural network library, to classify neural signals"
      ],
      "metadata": {
        "id": "uDiGAnjG_-pT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each column in this data is a recording location from EEG. The goal of this problem is to guess is the eye open or closed?"
      ],
      "metadata": {
        "id": "C-erbJpzc8ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def generate_synthetic_eeg(num_samples, num_channels=8, sequence_length=200):\n",
        "    time = np.linspace(0, 1, sequence_length)\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        if np.random.random() > 0.5:  # Eyes open\n",
        "            alpha_power = np.random.uniform(0.7, .9)\n",
        "            beta_power = np.random.uniform(1.0, 1.2)\n",
        "            label = 1\n",
        "        else:  # Eyes closed\n",
        "            alpha_power = np.random.uniform(1.0, 1.2)\n",
        "            beta_power = np.random.uniform(0.7, .9)\n",
        "            label = 0\n",
        "\n",
        "        sample = []\n",
        "        for channel in range(num_channels):\n",
        "            # Generate alpha waves (8-13 Hz)\n",
        "            alpha_freq = np.random.uniform(8, 13)\n",
        "            alpha_amplitude = alpha_power * np.random.uniform(0.5, 1.5)\n",
        "            alpha_phase = np.random.uniform(0, 2 * np.pi)\n",
        "            alpha_wave = alpha_amplitude * np.sin(2 * np.pi * alpha_freq * time + alpha_phase)\n",
        "\n",
        "            # Generate beta waves (13-30 Hz)\n",
        "            beta_freq = np.random.uniform(13, 30)\n",
        "            beta_amplitude = beta_power * np.random.uniform(0.5, 1.5)\n",
        "            beta_phase = np.random.uniform(0, 2 * np.pi)\n",
        "            beta_wave = beta_amplitude * np.sin(2 * np.pi * beta_freq * time + beta_phase)\n",
        "\n",
        "            # Combine waves\n",
        "            combined_wave = alpha_wave + beta_wave\n",
        "\n",
        "            # Add pink noise\n",
        "            pink_noise = np.random.normal(0, 1, sequence_length)\n",
        "            pink_noise = np.cumsum(pink_noise) / np.sqrt(np.arange(1, len(pink_noise) + 1))\n",
        "            pink_noise = pink_noise / np.std(pink_noise) * 0.1  # Adjust noise level\n",
        "\n",
        "            channel_data = combined_wave + pink_noise\n",
        "            sample.append(channel_data)\n",
        "\n",
        "        data.append(np.array(sample).T)  # Transpose to get (sequence_length, num_channels)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Generate synthetic data\n",
        "num_samples = 2000\n",
        "num_channels = 20\n",
        "sequence_length = 200\n",
        "\n",
        "X, y = generate_synthetic_eeg(num_samples, num_channels, sequence_length)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a PyTorch Dataset\n",
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.FloatTensor(X)\n",
        "        self.y = torch.LongTensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_dataset = EEGDataset(X_train, y_train)\n",
        "test_dataset = EEGDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Visualize some samples\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    sample_idx = np.random.randint(0, len(X))\n",
        "    plt.plot(X[sample_idx])\n",
        "    plt.title(f\"Eye State: {'Open' if y[sample_idx] == 1 else 'Closed'}\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Amplitude\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Total number of samples: {num_samples}\")\n",
        "print(f\"Number of channels: {num_channels}\")\n",
        "print(f\"Sequence length: {sequence_length}\")\n",
        "print(f\"Shape of a single sample: {X[0].shape}\")\n",
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of test samples: {len(X_test)}\")\n",
        "print(f\"Number of batches in training set: {len(train_loader)}\")\n",
        "print(f\"Number of batches in test set: {len(test_loader)}\")"
      ],
      "metadata": {
        "id": "p0zxltiHkN6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our first step in Pytorch is turn turn our data into a _DataLoader_. This helps organize our data in a way that makes it easy to do all the data wrangling the training algorithm has to do."
      ],
      "metadata": {
        "id": "r2pnSxoffBSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class EEG1DCNN(nn.Module):\n",
        "    def __init__(self, input_channels, sequence_length):\n",
        "        super(EEG1DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(input_channels, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(32 * (sequence_length // 4), 32)\n",
        "        self.fc2 = nn.Linear(32, 2)  # 2 classes: eyes open or closed\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # Change shape to (batch, channels, sequence_length)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sVAj2PBEgiWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# Hyperparameters\n",
        "input_channels = num_channels\n",
        "learning_rate = 0.001\n",
        "num_epochs = 30\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the model\n",
        "model = EEG1DCNN(input_channels, sequence_length).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_predictions, train_labels = [], []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_predictions.extend(predicted.cpu().numpy())\n",
        "            train_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_accuracy = accuracy_score(train_labels, train_predictions)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_predictions, val_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels.squeeze())\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_predictions.extend(predicted.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(val_loss)\n",
        "        train_accs.append(train_accuracy)\n",
        "        test_accs.append(val_accuracy)\n",
        "        if i % 5 == 0:\n",
        "          print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "          print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "          print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "          print('-' * 60)\n",
        "    return train_losses, test_losses, train_accs, test_accs\n",
        "\n",
        "# Train the model\n",
        "train_loss, test_loss, train_accs, test_accs = train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs)\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'eeg_1dcnn_model.pth')\n",
        "print(\"Model saved as 'eeg_1dcnn_model.pth'\")"
      ],
      "metadata": {
        "id": "BePoVFxbftqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's plot our train and validation accuracy over time!\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XG62npG2kAdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(test_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(test_accs, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o9GhtJofh0JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# When are we overfitting? What can we do about it?"
      ],
      "metadata": {
        "id": "bLjMfVemtJ1f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Dh3eqYrtMX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}